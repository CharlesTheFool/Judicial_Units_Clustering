{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: ['jurisprudencia', 'extraordinaria', 'vice presidencia', 'camaras', 'orgao', 'protocolo', 'centro', 'cartorio', 'juiz', 'judiciaria', 'controle', 'vara', 'processamento', 'apoio', 'unificada', 'consumidor', 'juizado', 'prudente']\n",
      "Kingdom: ['coman', 'tutelar', 'ativa', 'operacional', 'mista', 'vinculada', 'pericias', 'gabinete', 'proger', 'diretoria', 'processual', 'distribuicao', 'servico', 'judiciario', 'civel', 'turmas', 'virtual', 'contra', 'pg3', 'execucao', 'justica', 'criminais', 'civeis', 'sucessoes', 'publicos']\n",
      "Phylum: ['dtr', 'trf', 'substituto', 'camara', 'unica', 'auxiliar', 'assessoria', 'secao', 'sede', 'nucleo', 'recursal', 'itinerante', 'divisao', 'consumo', 'violencia', 'pre', 'central', 'tribunal', 'uniformizacao', 'alto', 'inativo', 'fazenda', 'posto', 'coordenadoria', 'fazendas', 'governador', 'infancia', 'contagem', 'penais', 'penal']\n",
      "Class: ['cumulativa', 'plena', 'bacenjud', 'ssj', 'dcp', 'microrregiao', 'titular', 'custodia', 'auditoria', 'eleitoral', 'circunscricao', 'subsecao', 'divida', 'distribuidor', 'regiao', 'cidadania', 'mediacao', 'gerencia', 'relatoria', 'cumprimento', 'direito', 'fiscal', 'comerciais', 'execucoes', 'forum', 'especial', 'secretaria', 'familia', 'domestica', 'crimes', 'registros']\n",
      "Order: ['direcao', 'exmo', 'relator', 'cump', 'federal', 'contadoria', 'jurisdicao', 'colegio', 'unico', 'grupo', 'anexo', 'comarca', 'publicas', 'atendimento', 'especializada', 'regime', 'integrado', 'trabalho', 'julgamento', 'conflitos', 'precatorios', 'estadual', 'gestao', 'medidas', 'judiciais', 'juizados', 'geral', 'desativada', 'juri', 'casa', 'relacoes', 'corregedoria']\n",
      "Family: ['em grau', 'ministro', 'migrada', 'jurista', 'sef', 'desembargador', 'zona', 'plantonista', 'conselho', 'pleno', 'extinta', 'mandados', 'plantao', 'turma', 'conciliacao', 'adjunto', 'judicial', 'transito', 'mulher', 'audiencia', 'alternativas', 'empresarial', 'fiscais', 'processos', 'inativa', 'unidade', 'feitos', 'juventude', 'foro', 'publica', 'militar', 'publico', 'dolosos']\n",
      "Genus: ['suplente', 'rel', 'convocado', 'privado', 'juizo', 'administracao', 'oficio', 'termo', 'recursos', 'segundo grau', 'sistema', 'solucao', 'avancado', 'setor', 'municipal', 'arquivo', 'presidencia', 'criminal', 'orfaos', 'jurisdicional', 'estado', 'regional', 'pessoa', 'presidente', 'capital', 'jundiai', 'distrito', 'familiar', 'precatorias', 'varas', 'relativos', 'primeiro grau', 'registro', 'crime', 'acidentes', 'extrajudicial']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import unicodedata\n",
    "import csv\n",
    "\n",
    "# Load the dataset (only the 'nomeUnidade' column)\n",
    "df = pd.read_csv('unidades.csv', usecols=['nomeUnidade'])\n",
    "\n",
    "# Display the first few rows to verify data\n",
    "df.head()\n",
    "\n",
    "# Load hierarchical groups from CSV\n",
    "hierarchical_groups = {}\n",
    "with open('hierarchical_groups.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        level, token = row\n",
    "        if level in hierarchical_groups:\n",
    "            hierarchical_groups[level].append(token)\n",
    "        else:\n",
    "            hierarchical_groups[level] = [token]\n",
    "\n",
    "# Display the hierarchical groups to verify\n",
    "for name, group in hierarchical_groups.items():\n",
    "    print(f\"{name}: {group}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove accents\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "# Define synonyms\n",
    "synonyms = {\n",
    "    'gab': 'gabinete',\n",
    "    'gab.': 'gabinete',\n",
    "    'presidencia': 'presidencia',\n",
    "    'v': 'vara',\n",
    "    'vio': 'violencia',\n",
    "    'c': 'circunscricao',\n",
    "    'juiza': 'juiz',\n",
    "    'substituta': 'substituto',\n",
    "    'faz': 'fazenda',\n",
    "    'fam': 'familia',\n",
    "    'exma': 'exmo',\n",
    "    'reg': 'registros',\n",
    "    'pub': 'publico',\n",
    "    'juv': 'juventude',\n",
    "    'inf': 'infancia',\n",
    "    'crim': 'criminal',\n",
    "    'DEECRIM': 'criminal',\n",
    "    'adj': 'adjunto',\n",
    "    'cons': 'consumo',\n",
    "    'jef': 'federal',\n",
    "    'jud': 'judiciario',\n",
    "    'desembargadora': 'desembargador',\n",
    "    'des': 'desembargador',\n",
    "    'desa': 'desembargador',\n",
    "    'desemb': 'desembargador',\n",
    "    'j': 'juizado',\n",
    "    'jui': 'juizado',\n",
    "    'civ': 'civel',\n",
    "    'esp': 'especial',\n",
    "    'especiais': 'especial'\n",
    "    # Add more synonyms as needed\n",
    "}\n",
    "\n",
    "# Define multi-token replacements\n",
    "multi_token_replacements = {\n",
    "    'vt': ['vara', 'trabalho'],\n",
    "    'cejusc': ['centro', 'judicial', 'solucao', 'conflitos', 'cidadania'],\n",
    "    'tr': ['turma', 'recursal'],\n",
    "    'jit': ['juizado', 'especial', 'civel'],\n",
    "    'gades': ['gabinete', 'desembargador'],\n",
    "    'jesp': ['juizado', 'especial', 'criminal'],\n",
    "    'jec': ['juizado', 'especial', 'civel'],\n",
    "    'saf': ['servico', 'anexo', 'fazendas'],\n",
    "    # Add more multi-token replacements as needed\n",
    "}\n",
    "\n",
    "# Function to replace synonyms and multi-token replacements\n",
    "def replace_synonyms_and_multi_tokens(token):\n",
    "    if token in multi_token_replacements:\n",
    "        return multi_token_replacements[token]\n",
    "    else:\n",
    "        return [synonyms.get(token, token)]\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_name(name, additional_stopwords=None):\n",
    "    name = remove_accents(name).lower()\n",
    "    \n",
    "    # REPLACE 'CJ' OR 'C J' WITH 'CIRCUNSCRICAO JUDICIAL'\n",
    "    name = re.sub(r'\\bc\\s*j\\b', 'circunscricao', name)\n",
    "    \n",
    "    # REMOVE NUMBERS AND NUMBER-LETTER COMBINATIONS, BUT KEEP THE PRECEDING WORD\n",
    "    name = re.sub(r'\\b(\\d+\\w*)\\b', '', name)\n",
    "    \n",
    "    # COMBINE 'GRAU' WITH THE PRECEDING WORD\n",
    "    name = re.sub(r'(\\b\\w+\\b)\\s+grau', r'\\1_grau', name)\n",
    "    \n",
    "    # COMBINE 'VICE' WITH THE FOLLOWING WORD (WITH SPACE OR HYPHEN) INTO A SINGLE TOKEN\n",
    "    name = re.sub(r'\\b(vice)[-\\s]+(\\w+)', r'\\1_\\2', name)\n",
    "    \n",
    "    tokens = re.split(r'\\s|,|\\.|\\(|\\)|-', name)\n",
    "\n",
    "    stopwords = ['de', 'da', 'do', 'das', 'dos', \n",
    "                 'e', 'a', 'o', 'i', 'u', 'b', 'as', 'ao',\n",
    "                 '\"', 'em', 'des', 'com', 'n',\n",
    "                 'rio', 'paulo', 'sao', 'bom', 'monte', 'montes', 'jesus', 'boa', 'ponta',\n",
    "                 'joao', 'jose', 'maria', 'santa','ferreira', 'martins', 'alves','antonio','luis', 'santos',\n",
    "                 'porto', 'belo', 'nova', 'sul', 'campo', 'oliveira','luiz','fortaleza', 'goiania', 'curitiba', 'silvia',\n",
    "                 'carlos','grande','silva','francisco', 'pedro', 'lucas','ana', 'francisca', 'antonia','juliana', 'julia','fernando',\n",
    "                 'fernanda','marcos','gabriel','adriana','marcia','souza','sousa','rodrigues','aves','pereira','lima','costa',\n",
    "                 'dr','dra', 'janeiro','vitoria','salvador','brasilia','fortaleza','horizonte','manaus','curitiba','recife','goiania',\n",
    "                 'santo','campos','filho','natal', 'primeira', 'segunda','iguacu','santana', 'preto','barra','funda','alegre',\n",
    "                 'alegre/rs','norte','cruz','sr', 'sra', 'cuiaba','belem','paulista','serra','ribeirao','neto','piaui','eduardo','roberto',\n",
    "                 'caxias','campinas','terceira','sul/rs','branco','almeida','novo','miguel','andre','carvalho','londrina','guarulhos',\n",
    "                 'goncalo', 'aparecida', 'sebastiao','teresina','/','ribeiro','gomes','campina','augusto','verde', 'ii','i','iii',\n",
    "                 'ricardo', 'bernardo','niteroi', 'vila','maringa','rocha','alberto','sorocaba','uberlandia','dois','tres','oeste','leste',\n",
    "                 'ap','amaro','cesar','machado','jorge','castro', 'marcelo', 'minas','henrique', 'cabo','vista','guimaraes', 'alexandre',\n",
    "                 'aracaju', 'cascavel', 'vicente', 'assis', 'lopes', 'velho', 'moraes', 'goncalves', 'conceicao', 'foz','franca','neves',\n",
    "                 'mendes','marques', 'cruzes', 'mogi', \"em grau\", 'grossa','feira', 'mesquita', 'rosa', 'junior','teixeira', 'jardim',\n",
    "                 'lagoas', 'fernandes', 'varzea', 'pinheiro', 'duque', 'aguas', 'goias', 'araujo', 'barbosa', 'nogueira', 'cristina',\n",
    "                 'guararapes', 'taguatinga', 'dias', 'helena', 'bauru', 'cunha', 'quarta','penas', 'sergio', 'soares', 'joinville',\n",
    "                 'claro','andrade', 'macapa', 'gama', 'pinto', 'mt', 'juazeiro', 'batista', 'jaboatao', 'ms', 'freitas', 'vieira', 'palmas',\n",
    "                 'mossoro', 'osasco', 'piracicaba', 'joaquim', 'patos', 'vida', 'pinhais', 'petropolis', 'marco', 'saude', 'coelho', 'reis',\n",
    "                 'lucia', 'fonseca', 'branca', 'olinda', 'anapolis', 'parnaiba', 'df', 'aracatuba', 'toledo', 'claudio', 'leite', 'fora']\n",
    "    if additional_stopwords:\n",
    "        stopwords.extend(additional_stopwords)\n",
    "    \n",
    "    # Process each token, applying synonyms and multi-token replacements\n",
    "    processed_tokens = []\n",
    "    skip_next = False\n",
    "    for i, token in enumerate(tokens):\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            continue\n",
    "        if token and token not in stopwords:\n",
    "            # Handle case where 'C' is followed by 'J'\n",
    "            if token == 'c' and i + 1 < len(tokens) and tokens[i + 1] == 'j':\n",
    "                processed_tokens.append('circunscricao')\n",
    "                skip_next = True\n",
    "            else:\n",
    "                processed_tokens.extend(replace_synonyms_and_multi_tokens(token))\n",
    "    \n",
    "    # Replace underscores with spaces in preserved conjoined expressions\n",
    "    processed_tokens = [token.replace('_', ' ') for token in processed_tokens]\n",
    "    return processed_tokens\n",
    "\n",
    "# Apply tokenization\n",
    "df['tokens'] = df['nomeUnidade'].apply(lambda x: tokenize_name(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomeUnidade</th>\n",
       "      <th>tokens</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAB. JUIZ JOSE CARLOS COELHO E SOUZA</td>\n",
       "      <td>[gabinete, juiz]</td>\n",
       "      <td>juiz:gabinete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CENTRAL DE MANDADOS DE BLUMENAU</td>\n",
       "      <td>[central, mandados, blumenau]</td>\n",
       "      <td>central:mandados | blumenau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2ª VARA FEDERAL DE BLUMENAU</td>\n",
       "      <td>[vara, federal, blumenau]</td>\n",
       "      <td>vara:federal | blumenau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ª VARA FEDERAL DE BLUMENAU</td>\n",
       "      <td>[vara, federal, blumenau]</td>\n",
       "      <td>vara:federal | blumenau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ª VARA FEDERAL DE BLUMENAU</td>\n",
       "      <td>[vara, federal, blumenau]</td>\n",
       "      <td>vara:federal | blumenau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            nomeUnidade                         tokens  \\\n",
       "0  GAB. JUIZ JOSE CARLOS COELHO E SOUZA               [gabinete, juiz]   \n",
       "1       CENTRAL DE MANDADOS DE BLUMENAU  [central, mandados, blumenau]   \n",
       "2           2ª VARA FEDERAL DE BLUMENAU      [vara, federal, blumenau]   \n",
       "3           3ª VARA FEDERAL DE BLUMENAU      [vara, federal, blumenau]   \n",
       "4           4ª VARA FEDERAL DE BLUMENAU      [vara, federal, blumenau]   \n",
       "\n",
       "                classification  \n",
       "0                juiz:gabinete  \n",
       "1  central:mandados | blumenau  \n",
       "2      vara:federal | blumenau  \n",
       "3      vara:federal | blumenau  \n",
       "4      vara:federal | blumenau  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to categorize tokens based on hierarchical groups\n",
    "def categorize_token_by_hierarchy(token, hierarchical_groups):\n",
    "    for name, group in hierarchical_groups.items():\n",
    "        if token in group:\n",
    "            return name\n",
    "    return 'other'\n",
    "\n",
    "# Function to calculate expressivity ratio for a token in relation to a group\n",
    "def calculate_expressivity_ratio(token, group, token_stats):\n",
    "    word_count = token_stats[token]['count']\n",
    "    cooccurrence_count = sum(token_stats[token]['cooccurrences'].get(t, 0) for t in group)\n",
    "    return 1 - (cooccurrence_count / word_count) if word_count > 0 else 0\n",
    "\n",
    "# Calculate token statistics\n",
    "token_stats = {token: {'count': count, 'cooccurrences': defaultdict(int)} for token, count in Counter([token for tokens_row in df['tokens'] for token in tokens_row]).items()}\n",
    "\n",
    "for tokens_row in df['tokens']:\n",
    "    for token in tokens_row:\n",
    "        if token in token_stats:\n",
    "            for co_token in tokens_row:\n",
    "                if co_token != token:\n",
    "                    token_stats[token]['cooccurrences'][co_token] += 1\n",
    "\n",
    "# Create hierarchical classification for each entry and choose species\n",
    "def classify_entry(tokens, hierarchical_groups, token_stats):\n",
    "    classification = {}\n",
    "    unclassified_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        level = categorize_token_by_hierarchy(token, hierarchical_groups)\n",
    "        if level != 'other':\n",
    "            if level in classification:\n",
    "                classification[level].append(token)\n",
    "            else:\n",
    "                classification[level] = [token]\n",
    "        else:\n",
    "            unclassified_tokens.append(token)\n",
    "    \n",
    "    # Order by hierarchy\n",
    "    ordered_classification = {level: sorted(classification.get(level, [])) for level in hierarchical_groups.keys()}\n",
    "    \n",
    "    # Calculate expressivity ratio for unclassified tokens\n",
    "    species_token = None\n",
    "    lowest_avg_expressivity = float('inf')\n",
    "    for token in unclassified_tokens:\n",
    "        avg_expressivity = np.mean([calculate_expressivity_ratio(token, group, token_stats) for group in hierarchical_groups.values()])\n",
    "        if avg_expressivity < lowest_avg_expressivity:\n",
    "            lowest_avg_expressivity = avg_expressivity\n",
    "            species_token = token\n",
    "    \n",
    "    # Create a combined notation\n",
    "    combined_classification = \":\".join([\",\".join(ordered_classification[level]) for level in ordered_classification if ordered_classification[level]])\n",
    "    if species_token:\n",
    "        combined_classification += f\" | {species_token}\"\n",
    "    \n",
    "    return combined_classification\n",
    "\n",
    "df['classification'] = df['tokens'].apply(lambda x: classify_entry(x, hierarchical_groups, token_stats))\n",
    "\n",
    "# Display the classified entries\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomeUnidade</th>\n",
       "      <th>tokens</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19617</th>\n",
       "      <td>0POSSE - 1ª VARA (CÍVEL, CRIMINAL %u2013 CRIME...</td>\n",
       "      <td>[vara, civel, criminal, %u2013, crimes, geral,...</td>\n",
       "      <td>%u2013 | criminal  | juventude | geral | crim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19868</th>\n",
       "      <td>0 CEJUSC - Abaeté (Pré-Processual)</td>\n",
       "      <td>[centro, judicial, solucao, conflitos, cidadan...</td>\n",
       "      <td>abaete | solucao  | judicial | conflitos | ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11769</th>\n",
       "      <td>CEJUSC - PRE-PROCESSUAL - POSTO SAUDE-ABRAMGE</td>\n",
       "      <td>[centro, judicial, solucao, conflitos, cidadan...</td>\n",
       "      <td>abramge | solucao  | judicial | conflitos | c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11755</th>\n",
       "      <td>CEJUSC - PRE-PROCESSUAL - ACE</td>\n",
       "      <td>[centro, judicial, solucao, conflitos, cidadan...</td>\n",
       "      <td>ace | solucao  | judicial | conflitos | cidad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22225</th>\n",
       "      <td>VARA DOS FEITOS RELATIVOS ÀS RELAÇÕES DE CONSU...</td>\n",
       "      <td>[vara, feitos, relativos, relacoes, consumo, c...</td>\n",
       "      <td>acidente | registro,relativos  | feitos,publi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             nomeUnidade  \\\n",
       "19617  0POSSE - 1ª VARA (CÍVEL, CRIMINAL %u2013 CRIME...   \n",
       "19868                 0 CEJUSC - Abaeté (Pré-Processual)   \n",
       "11769      CEJUSC - PRE-PROCESSUAL - POSTO SAUDE-ABRAMGE   \n",
       "11755                      CEJUSC - PRE-PROCESSUAL - ACE   \n",
       "22225  VARA DOS FEITOS RELATIVOS ÀS RELAÇÕES DE CONSU...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "19617  [vara, civel, criminal, %u2013, crimes, geral,...   \n",
       "19868  [centro, judicial, solucao, conflitos, cidadan...   \n",
       "11769  [centro, judicial, solucao, conflitos, cidadan...   \n",
       "11755  [centro, judicial, solucao, conflitos, cidadan...   \n",
       "22225  [vara, feitos, relativos, relacoes, consumo, c...   \n",
       "\n",
       "                                          classification  \n",
       "19617   %u2013 | criminal  | juventude | geral | crim...  \n",
       "19868   abaete | solucao  | judicial | conflitos | ci...  \n",
       "11769   abramge | solucao  | judicial | conflitos | c...  \n",
       "11755   ace | solucao  | judicial | conflitos | cidad...  \n",
       "22225   acidente | registro,relativos  | feitos,publi...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split classification into hierarchical levels and species\n",
    "df[['Domain', 'Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']] = df['classification'].str.split('[:|]', expand=True)\n",
    "\n",
    "# Initial alphabetical sort for all entries\n",
    "df = df.sort_values(by=['classification'])\n",
    "\n",
    "# Ground-up alphabetical ordering for each level\n",
    "hierarchical_levels = ['Species', 'Genus', 'Family', 'Order', 'Class', 'Phylum', 'Kingdom', 'Domain']\n",
    "\n",
    "for level in hierarchical_levels:\n",
    "    if level in df.columns:\n",
    "        df = df.sort_values(by=hierarchical_levels[:hierarchical_levels.index(level) + 1])\n",
    "\n",
    "# Combine classification back into a single string\n",
    "df['classification'] = df[hierarchical_levels].apply(lambda x: ' | '.join(x.dropna()), axis=1)\n",
    "\n",
    "# Drop the temporary hierarchical columns\n",
    "df = df.drop(columns=hierarchical_levels)\n",
    "\n",
    "# Export classified entries to a new CSV\n",
    "df[['nomeUnidade', 'classification']].to_csv('classified_unidades.csv', index=False)\n",
    "\n",
    "# Display the final sorted DataFrame\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
